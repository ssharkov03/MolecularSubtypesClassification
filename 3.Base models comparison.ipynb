{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ff6708-ff47-45bf-8d17-b18bb1cc1f13",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e761922-2ff4-4172-826c-a0aecabde099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07dc4a2-5d3a-47a2-bde5-946a2f0427c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mljar-supervised\n",
    "from supervised.automl import AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3696fe-db6d-4d38-9dd3-db477ee88024",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9c5c94-ca28-4dc5-ba7a-8841ee4abfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Saved data/X_train.pickle', 'rb') as data:\n",
    "    X_train = pickle.load(data)\n",
    "    \n",
    "with open('Saved data/X_test.pickle', 'rb') as data:\n",
    "    X_test = pickle.load(data)\n",
    "\n",
    "with open('Saved data/X_train_scaled.pickle', 'rb') as data:\n",
    "    X_train_scaled = pickle.load(data)\n",
    "    \n",
    "with open('Saved data/X_test_scaled.pickle', 'rb') as data:\n",
    "    X_test_scaled = pickle.load(data)\n",
    "    \n",
    "with open('Saved data/X_train_pca.pickle', 'rb') as data:\n",
    "    X_train_pca = pickle.load(data)\n",
    "    \n",
    "with open('Saved data/X_test_pca.pickle', 'rb') as data:\n",
    "    X_test_pca = pickle.load(data)\n",
    "    \n",
    "with open('Saved data/X_train_autoencoder.pickle', 'rb') as data:\n",
    "    X_train_autoencoder = pickle.load(data)\n",
    "    \n",
    "with open('Saved data/X_test_autoencoder.pickle', 'rb') as data:\n",
    "    X_test_autoencoder = pickle.load(data)\n",
    "    \n",
    "with open('Saved data/y_train.pickle', 'rb') as data:\n",
    "    y_train = pickle.load(data)\n",
    "    \n",
    "with open('Saved data/y_test.pickle', 'rb') as data:\n",
    "    y_test = pickle.load(data)\n",
    "    \n",
    "with open('Saved data/labels.pickle', 'rb') as data:\n",
    "    labels = pickle.load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b24ff7-3e4b-41f1-a775-5ca79e8622d6",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "155c7acd-0dde-46cb-9ec5-eb47da2319c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.90      0.95        20\n",
      "        Her2       0.80      0.73      0.76        22\n",
      "        LumA       0.90      0.94      0.92        68\n",
      "        LumB       0.81      0.83      0.82        46\n",
      "\n",
      "    accuracy                           0.87       156\n",
      "   macro avg       0.88      0.85      0.86       156\n",
      "weighted avg       0.87      0.87      0.87       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "randforestClassifier = RandomForestClassifier()\n",
    "randforestClassifier.fit(X_train, y_train)\n",
    "randforestPredictions = randforestClassifier.predict(X_test)\n",
    "print(classification_report(y_test, randforestPredictions, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed1d2d7f-e6d6-49a9-92db-b2ceb2a53eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.85      0.92        20\n",
      "        Her2       0.78      0.64      0.70        22\n",
      "        LumA       0.92      0.96      0.94        68\n",
      "        LumB       0.80      0.87      0.83        46\n",
      "\n",
      "    accuracy                           0.87       156\n",
      "   macro avg       0.87      0.83      0.85       156\n",
      "weighted avg       0.87      0.87      0.87       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest + Scaled\n",
    "randforestClassifierScaled = RandomForestClassifier()\n",
    "randforestClassifierScaled.fit(X_train_scaled, y_train)\n",
    "randforestPredictionsScaled = randforestClassifierScaled.predict(X_test_scaled)\n",
    "print(classification_report(y_test, randforestPredictionsScaled, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e3a894f-59ae-487a-a375-71e863a817f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.35      0.52        20\n",
      "        Her2       1.00      0.23      0.37        22\n",
      "        LumA       0.51      1.00      0.68        68\n",
      "        LumB       0.64      0.15      0.25        46\n",
      "\n",
      "    accuracy                           0.56       156\n",
      "   macro avg       0.79      0.43      0.45       156\n",
      "weighted avg       0.68      0.56      0.49       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest + PCA\n",
    "randforestClassifierPCA = RandomForestClassifier()\n",
    "randforestClassifierPCA.fit(X_train_pca, y_train)\n",
    "randforestPredictionsPCA = randforestClassifierPCA.predict(X_test_pca)\n",
    "print(classification_report(y_test, randforestPredictionsPCA, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769285f-3809-4864-a62e-11312c4f5e78",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68487de-a883-426c-bf0e-d4c52b1b4a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.95      0.97        20\n",
      "        Her2       0.85      0.77      0.81        22\n",
      "        LumA       0.93      0.96      0.94        68\n",
      "        LumB       0.87      0.89      0.88        46\n",
      "\n",
      "    accuracy                           0.91       156\n",
      "   macro avg       0.91      0.89      0.90       156\n",
      "weighted avg       0.91      0.91      0.91       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "logregClassifier = LogisticRegression()\n",
    "logregClassifier.fit(X_train, y_train)\n",
    "logregPredictions = logregClassifier.predict(X_test)\n",
    "print(classification_report(y_test, logregPredictions, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07790fcc-8bfe-4f96-bbc0-fbd8c3b228e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.90      0.95        20\n",
      "        Her2       0.86      0.82      0.84        22\n",
      "        LumA       0.94      0.96      0.95        68\n",
      "        LumB       0.85      0.89      0.87        46\n",
      "\n",
      "    accuracy                           0.91       156\n",
      "   macro avg       0.91      0.89      0.90       156\n",
      "weighted avg       0.91      0.91      0.91       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression + Scaled\n",
    "logregClassifierScaled = LogisticRegression()\n",
    "logregClassifierScaled.fit(X_train_scaled, y_train)\n",
    "logregPredictionsScaled = logregClassifierScaled.predict(X_test_scaled)\n",
    "print(classification_report(y_test, logregPredictionsScaled, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85cafbd9-7182-40db-be65-745536e5a506",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.90      0.95        20\n",
      "        Her2       0.85      0.77      0.81        22\n",
      "        LumA       0.94      0.94      0.94        68\n",
      "        LumB       0.82      0.89      0.85        46\n",
      "\n",
      "    accuracy                           0.90       156\n",
      "   macro avg       0.90      0.88      0.89       156\n",
      "weighted avg       0.90      0.90      0.90       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression + PCA\n",
    "logregClassifierPCA = LogisticRegression()\n",
    "logregClassifierPCA.fit(X_train_pca, y_train)\n",
    "logregPredictionsPCA = logregClassifierPCA.predict(X_test_pca)\n",
    "print(classification_report(y_test, logregPredictionsPCA, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409019e6-ee8c-4067-b4c0-f761e75a2b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.95      0.90      0.92        20\n",
      "        Her2       0.90      0.82      0.86        22\n",
      "        LumA       0.82      0.88      0.85        68\n",
      "        LumB       0.75      0.72      0.73        46\n",
      "\n",
      "    accuracy                           0.83       156\n",
      "   macro avg       0.85      0.83      0.84       156\n",
      "weighted avg       0.83      0.83      0.83       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression + AutoEncoder\n",
    "logregClassifierAE = LogisticRegression()\n",
    "logregClassifierAE.fit(X_train_autoencoder, y_train)\n",
    "logregPredictionsAE = logregClassifierAE.predict(X_test_autoencoder)\n",
    "print(classification_report(y_test, logregPredictionsAE, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec88b28-d6cf-4c8b-83e0-8a21270c1919",
   "metadata": {},
   "source": [
    "## Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe2507b4-2121-4f9d-b000-4e93b2a963cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.90      0.95        20\n",
      "        Her2       0.88      0.64      0.74        22\n",
      "        LumA       0.91      0.94      0.93        68\n",
      "        LumB       0.81      0.91      0.86        46\n",
      "\n",
      "    accuracy                           0.88       156\n",
      "   macro avg       0.90      0.85      0.87       156\n",
      "weighted avg       0.89      0.88      0.88       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RidgeClassifier\n",
    "ridgeClassifier = RidgeClassifier()\n",
    "ridgeClassifier.fit(X_train, y_train)\n",
    "ridgePredictions = ridgeClassifier.predict(X_test)\n",
    "print(classification_report(y_test, ridgePredictions, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2040edef-cd66-4cdd-97d3-2e2041b5a5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.90      0.95        20\n",
      "        Her2       0.88      0.64      0.74        22\n",
      "        LumA       0.91      0.94      0.93        68\n",
      "        LumB       0.81      0.91      0.86        46\n",
      "\n",
      "    accuracy                           0.88       156\n",
      "   macro avg       0.90      0.85      0.87       156\n",
      "weighted avg       0.89      0.88      0.88       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RidgeClassifier + Scaled\n",
    "ridgeClassifierScaled = RidgeClassifier()\n",
    "ridgeClassifierScaled.fit(X_train_scaled, y_train)\n",
    "ridgePredictionsScaled = ridgeClassifierScaled.predict(X_test_scaled)\n",
    "print(classification_report(y_test, ridgePredictionsScaled, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5018158-ab92-4acc-97a5-0c786fb2751d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.90      0.95        20\n",
      "        Her2       0.84      0.73      0.78        22\n",
      "        LumA       0.88      0.90      0.89        68\n",
      "        LumB       0.78      0.85      0.81        46\n",
      "\n",
      "    accuracy                           0.86       156\n",
      "   macro avg       0.88      0.84      0.86       156\n",
      "weighted avg       0.86      0.86      0.86       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RidgeClassifier + PCA\n",
    "ridgeClassifierPCA = RidgeClassifier()\n",
    "ridgeClassifierPCA.fit(X_train_pca, y_train)\n",
    "ridgePredictionsPCA = ridgeClassifierPCA.predict(X_test_pca)\n",
    "print(classification_report(y_test, ridgePredictionsPCA, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34565f01-050a-40a6-a688-49864028d5ce",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13c85b28-b60b-44be-a06b-2e60eac46bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.80      0.89        20\n",
      "        Her2       0.69      0.82      0.75        22\n",
      "        LumA       0.91      0.94      0.93        68\n",
      "        LumB       0.82      0.78      0.80        46\n",
      "\n",
      "    accuracy                           0.86       156\n",
      "   macro avg       0.86      0.84      0.84       156\n",
      "weighted avg       0.87      0.86      0.86       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BayesClassifier\n",
    "bayesClassifier = GaussianNB()\n",
    "bayesClassifier.fit(X_train, y_train)\n",
    "bayesPredictions = bayesClassifier.predict(X_test)\n",
    "print(classification_report(y_test, bayesPredictions, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbe8426d-aa39-4825-90dc-55296a4a1117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.80      0.89        20\n",
      "        Her2       0.69      0.82      0.75        22\n",
      "        LumA       0.91      0.94      0.93        68\n",
      "        LumB       0.82      0.78      0.80        46\n",
      "\n",
      "    accuracy                           0.86       156\n",
      "   macro avg       0.86      0.84      0.84       156\n",
      "weighted avg       0.87      0.86      0.86       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BayesClassifier + Scaled\n",
    "bayesClassifierScaled = GaussianNB()\n",
    "bayesClassifierScaled.fit(X_train_scaled, y_train)\n",
    "bayesPredictionsScaled = bayesClassifierScaled.predict(X_test_scaled)\n",
    "print(classification_report(y_test, bayesPredictionsScaled, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77ec72bd-2b3e-4ef1-885a-c6e8d621828d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.00      0.00      0.00        20\n",
      "        Her2       0.00      0.00      0.00        22\n",
      "        LumA       0.44      1.00      0.61        68\n",
      "        LumB       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.44       156\n",
      "   macro avg       0.11      0.25      0.15       156\n",
      "weighted avg       0.19      0.44      0.26       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BayesClassifier + PCA\n",
    "bayesClassifierPCA = GaussianNB()\n",
    "bayesClassifierPCA.fit(X_train_pca, y_train)\n",
    "bayesPredictionsPCA = bayesClassifierPCA.predict(X_test_pca)\n",
    "print(classification_report(y_test, bayesPredictionsPCA, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93af966-cbfb-420d-894f-dcd74af34794",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "328ab214-474a-453f-98a1-1f7c829df639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.90      0.95        20\n",
      "        Her2       0.85      0.77      0.81        22\n",
      "        LumA       0.95      0.93      0.94        68\n",
      "        LumB       0.81      0.91      0.86        46\n",
      "\n",
      "    accuracy                           0.90       156\n",
      "   macro avg       0.90      0.88      0.89       156\n",
      "weighted avg       0.90      0.90      0.90       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svmClassifier = LinearSVC()\n",
    "svmClassifier.fit(X_train, y_train)\n",
    "svmPredictions = svmClassifier.predict(X_test)\n",
    "print(classification_report(y_test, svmPredictions, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c5f4266-175a-40f5-9af9-af220042fa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.90      0.95        20\n",
      "        Her2       0.84      0.73      0.78        22\n",
      "        LumA       0.94      0.91      0.93        68\n",
      "        LumB       0.79      0.91      0.85        46\n",
      "\n",
      "    accuracy                           0.88       156\n",
      "   macro avg       0.89      0.86      0.88       156\n",
      "weighted avg       0.89      0.88      0.89       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM + Scaled\n",
    "svmClassifierScaled = LinearSVC()\n",
    "svmClassifierScaled.fit(X_train_scaled, y_train)\n",
    "svmPredictionsScaled = svmClassifierScaled.predict(X_test_scaled)\n",
    "print(classification_report(y_test, svmPredictionsScaled, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4af3257b-28c6-4659-9757-5d7df8a2365e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       0.95      0.95      0.95        20\n",
      "        Her2       0.84      0.73      0.78        22\n",
      "        LumA       0.93      0.94      0.93        68\n",
      "        LumB       0.83      0.87      0.85        46\n",
      "\n",
      "    accuracy                           0.89       156\n",
      "   macro avg       0.89      0.87      0.88       156\n",
      "weighted avg       0.89      0.89      0.89       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM + PCA\n",
    "svmClassifierPCA = LinearSVC()\n",
    "svmClassifierPCA.fit(X_train_pca, y_train)\n",
    "svmPredictionsPCA = svmClassifierPCA.predict(X_test_pca)\n",
    "print(classification_report(y_test, svmPredictionsPCA, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061dbe78-3adb-4524-9f43-065772cb9f52",
   "metadata": {},
   "source": [
    "## AutoML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a0f9240-8883-40c0-b492-c57f7ef27ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear algorithm was disabled.\n",
      "AutoML directory: AutoML_1\n",
      "The task is multiclass_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['LightGBM', 'Neural Network']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 2 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 18:33:11,573 concurrent.futures ERROR exception calling callback for <Future at 0x11a15b923b0 state=finished raised BrokenProcessPool>\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\envs\\cancer\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 407, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"D:\\Anaconda\\envs\\cancer\\lib\\multiprocessing\\queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"D:\\Anaconda\\envs\\cancer\\lib\\site-packages\\lightgbm\\basic.py\", line 2690, in __setstate__\n",
      "    _safe_call(_LIB.LGBM_BoosterLoadModelFromString(\n",
      "  File \"D:\\Anaconda\\envs\\cancer\\lib\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: bad allocation\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\envs\\cancer\\lib\\site-packages\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"D:\\Anaconda\\envs\\cancer\\lib\\site-packages\\joblib\\parallel.py\", line 366, in __call__\n",
      "    The new backend can then be selected by passing its name as the backend\n",
      "  File \"D:\\Anaconda\\envs\\cancer\\lib\\site-packages\\joblib\\parallel.py\", line 799, in dispatch_next\n",
      "    \"\"\"Prefetch the tasks for the next batch and dispatch them.\n",
      "  File \"D:\\Anaconda\\envs\\cancer\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    # XXX: Not using the logger framework: need to\n",
      "  File \"D:\\Anaconda\\envs\\cancer\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    self._jobs.insert(job_idx, job)\n",
      "  File \"D:\\Anaconda\\envs\\cancer\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"D:\\Anaconda\\envs\\cancer\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py\", line 177, in submit\n",
      "    return super(_ReusablePoolExecutor, self).submit(\n",
      "  File \"D:\\Anaconda\\envs\\cancer\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 1102, in submit\n",
      "    mp.util.debug('Adjust process count : {}'.format(self._processes))\n",
      "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "Problem during computing permutation importance. Skipping ...\n",
      "1_Default_LightGBM logloss 0.462574 trained in 1476.02 seconds (1-sample predict time 12.6808 seconds)\n",
      "* Step not_so_random will try to check up to 8 models\n",
      "2_LightGBM logloss 0.35717 trained in 2857.26 seconds (1-sample predict time 12.9719 seconds)\n",
      "Skip golden_features because no parameters were generated.\n",
      "Skip insert_random_feature because no parameters were generated.\n",
      "Skip features_selection because no parameters were generated.\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble not trained. Can't contruct ensemble with prediction time smaller than limit.\n",
      "****************************************************************\n",
      "There were no model with prediction time smaller than the limit.\n",
      "Please increase the prediction time for single sample,\n",
      "or please to use train/test split for validation\n",
      "****************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 19:21:53,331 supervised.exceptions ERROR Missing column: feature_1 in input data. Cannot predict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML fit time: 4427.17 seconds\n",
      "AutoML best model: 2_LightGBM\n"
     ]
    },
    {
     "ename": "AutoMLException",
     "evalue": "Missing column: feature_1 in input data. Cannot predict",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAutoMLException\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m automl \u001b[38;5;241m=\u001b[39m AutoML(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerform\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m automl\u001b[38;5;241m.\u001b[39mfit(X_train_scaled\u001b[38;5;241m.\u001b[39mto_numpy(), y_train\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[1;32m----> 3\u001b[0m automlPredictions \u001b[38;5;241m=\u001b[39m \u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, automlPredictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy(), target_names\u001b[38;5;241m=\u001b[39mlabels))\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\cancer\\lib\\site-packages\\supervised\\automl.py:431\u001b[0m, in \u001b[0;36mAutoML.predict_all\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_all\u001b[39m(\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28mself\u001b[39m, X: Union[List, numpy\u001b[38;5;241m.\u001b[39mndarray, pandas\u001b[38;5;241m.\u001b[39mDataFrame]\n\u001b[0;32m    412\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;124;03m    Computes both class probabilities and class labels for classification tasks.\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;124;03m    Computes predictions for regression tasks.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    429\u001b[0m \n\u001b[0;32m    430\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\cancer\\lib\\site-packages\\supervised\\base_automl.py:1385\u001b[0m, in \u001b[0;36mBaseAutoML._predict_all\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_all\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1384\u001b[0m     \u001b[38;5;66;03m# Make and return predictions\u001b[39;00m\n\u001b[1;32m-> 1385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\cancer\\lib\\site-packages\\supervised\\base_automl.py:1308\u001b[0m, in \u001b[0;36mBaseAutoML._base_predict\u001b[1;34m(self, X, model)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m input_columns:\n\u001b[1;32m-> 1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m AutoMLException(\n\u001b[0;32m   1309\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing column: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in input data. Cannot predict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1310\u001b[0m         )\n\u001b[0;32m   1312\u001b[0m X \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n",
      "\u001b[1;31mAutoMLException\u001b[0m: Missing column: feature_1 in input data. Cannot predict"
     ]
    }
   ],
   "source": [
    "automl = AutoML(mode=\"Perform\")\n",
    "automl.fit(X_train_scaled.to_numpy(), y_train.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b55f822-59f1-48c5-a773-e03b4ca440df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Basal       1.00      0.95      0.97        20\n",
      "        Her2       0.89      0.77      0.83        22\n",
      "        LumA       0.93      1.00      0.96        68\n",
      "        LumB       0.91      0.89      0.90        46\n",
      "\n",
      "    accuracy                           0.93       156\n",
      "   macro avg       0.93      0.90      0.92       156\n",
      "weighted avg       0.93      0.93      0.93       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Saved to AutoML1_perform/2_LightGBM\n",
    "automlPredictions = automl.predict_all(X_test_scaled.to_numpy())\n",
    "print(classification_report(y_test, automlPredictions['label'].to_numpy(), target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c50cca9a-fc42-464a-b01a-2215cfa4680a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autoMLPerform93.pkl']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(automl, 'Saved models & utils/autoMLPerform93.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cancer",
   "language": "python",
   "name": "cancer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
